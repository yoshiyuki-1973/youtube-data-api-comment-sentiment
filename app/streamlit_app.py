"""YouTube Analytics - Streamlit Web UI."""

import re
import logging
import sys
import os
from pathlib import Path

import streamlit as st
import pandas as pd

from fetch.youtube import (
    fetch_video,
    fetch_comments,
    QuotaExceededError,
    AuthenticationError,
    VideoNotFoundError,
    CommentsDisabledError,
)
from sentiment.analyzer import classify_comments
from aggregate.summarizer import aggregate_video
from repository.mysql import save_video, save_summary, get_video, get_summary
from utils.cache import save_json, load_json

# Configure logging for Streamlit
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s %(name)s: %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# Page config
st.set_page_config(
    page_title="YouTube Comment Analyzer",
    page_icon="ğŸ“Š",
    layout="wide"
)


def extract_video_id(input_str: str) -> str | None:
    """
    Extract YouTube video ID from URL or direct ID.

    Supports:
    - https://www.youtube.com/watch?v=VIDEO_ID
    - https://youtu.be/VIDEO_ID
    - https://www.youtube.com/embed/VIDEO_ID
    - https://www.youtube.com/v/VIDEO_ID
    - VIDEO_ID (direct 11-character ID)

    Args:
        input_str: YouTube URL or video ID

    Returns:
        Video ID or None if invalid
    """
    input_str = input_str.strip()

    if not input_str:
        return None

    # Pattern for direct video ID (11 characters, alphanumeric + - _)
    direct_id_pattern = r'^[a-zA-Z0-9_-]{11}$'
    if re.match(direct_id_pattern, input_str):
        return input_str

    # Patterns for various YouTube URL formats
    url_patterns = [
        r'(?:https?://)?(?:www\.)?youtube\.com/watch\?v=([a-zA-Z0-9_-]{11})',
        r'(?:https?://)?(?:www\.)?youtube\.com/embed/([a-zA-Z0-9_-]{11})',
        r'(?:https?://)?(?:www\.)?youtube\.com/v/([a-zA-Z0-9_-]{11})',
        r'(?:https?://)?youtu\.be/([a-zA-Z0-9_-]{11})',
        r'(?:https?://)?(?:www\.)?youtube\.com/shorts/([a-zA-Z0-9_-]{11})',
    ]

    for pattern in url_patterns:
        match = re.search(pattern, input_str)
        if match:
            return match.group(1)

    return None


def get_comment_limit() -> int:
    """
    Get comment limit from environment variable.
    
    Returns:
        Comment limit (default: 10)
    """
    try:
        limit = int(os.environ.get('COMMENT_LIMIT', '10'))
        return max(1, min(limit, 100))  # 1-100ã®ç¯„å›²ã«åˆ¶é™
    except (ValueError, TypeError):
        logger.warning('COMMENT_LIMITè¨­å®šãŒç„¡åŠ¹ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤10ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚')
        return 10


def analyze_video(video_id: str, comment_limit: int, use_cache: bool = True) -> dict | None:
    """
    Analyze a YouTube video.

    Args:
        video_id: YouTube video ID
        comment_limit: Number of comments to fetch
        use_cache: Whether to use cached JSON data

    Returns:
        Analysis result dict or None if failed
    """
    # Try to load from cache
    if use_cache:
        cached_data = load_json(video_id)
        if cached_data:
            logger.info(f'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™: {video_id}')
            # Validate sentiment data format
            comments = cached_data.get('comments', [])
            needs_reclassification = False

            for comment in comments:
                sentiment = comment.get('sentiment')
                # Check if sentiment is valid dict with required keys
                if not isinstance(sentiment, dict) or \
                   not all(key in sentiment for key in ['positive', 'negative', 'neutral']):
                    needs_reclassification = True
                    logger.warning('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®sentimentå½¢å¼ãŒç„¡åŠ¹ã§ã™ã€‚å†åˆ†é¡ã—ã¾ã™ã€‚')
                    break

            # Re-classify if sentiment data is invalid
            if needs_reclassification:
                comments = classify_comments(comments)
                cached_data['comments'] = comments
                save_json(video_id, cached_data)  # Update cache

            video = {k: v for k, v in cached_data.items() if k != 'comments'}
            summary = aggregate_video(video, comments)
            save_video(video)
            save_summary(summary)
            return {
                'video': video,
                'comments': comments,
                'summary': summary
            }

    # Fetch video metadata
    video = fetch_video(video_id)
    if not video:
        return None

    # Fetch and classify comments
    comments = fetch_comments(video_id, comment_limit)
    comments = classify_comments(comments)

    # Aggregate results
    summary = aggregate_video(video, comments)

    # Save to JSON cache
    data = {**video, 'comments': comments}
    save_json(video_id, data)

    # Save to database
    save_video(video)
    save_summary(summary)

    return {
        'video': video,
        'comments': comments,
        'summary': summary
    }


def display_video_info(video: dict) -> None:
    """Display video information."""
    st.subheader("å‹•ç”»æƒ…å ±")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å†ç”Ÿå›æ•°", f"{video.get('view_count', 0):,}")
    with col2:
        st.metric("é«˜è©•ä¾¡æ•°", f"{video.get('like_count', 0):,}")
    with col3:
        st.metric("ã‚³ãƒ¡ãƒ³ãƒˆæ•°", f"{video.get('comment_count', 0):,}")

    st.markdown(f"**ã‚¿ã‚¤ãƒˆãƒ«**: {video.get('title', 'N/A')}")
    st.markdown(f"**ãƒãƒ£ãƒ³ãƒãƒ«**: {video.get('channel_title', 'N/A')}")
    st.markdown(f"**å…¬é–‹æ—¥**: {video.get('published_at', 'N/A')}")


def display_sentiment_summary(summary: dict) -> None:
    """Display sentiment analysis summary."""
    st.subheader("æ„Ÿæƒ…åˆ†æçµæœ")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("åˆ†æã‚³ãƒ¡ãƒ³ãƒˆæ•°", summary.get('total_comments', 0))
    with col2:
        positive_score = summary.get('positive_score', 0)
        st.metric(
            "ãƒã‚¸ãƒ†ã‚£ãƒ–",
            f"{positive_score:.4f}",
        )
    with col3:
        negative_score = summary.get('negative_score', 0)
        st.metric(
            "ãƒã‚¬ãƒ†ã‚£ãƒ–",
            f"{negative_score:.4f}",
        )
    with col4:
        neutral_score = summary.get('neutral_score', 0)
        st.metric("ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", f"{neutral_score:.4f}")

    # Sentiment bar chart
    if summary.get('total_comments', 0) > 0:
        chart_data = pd.DataFrame({
            'æ„Ÿæƒ…': ['ãƒã‚¸ãƒ†ã‚£ãƒ–', 'ãƒã‚¬ãƒ†ã‚£ãƒ–', 'ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«'],
            'ã‚¹ã‚³ã‚¢': [
                summary.get('positive_score', 0),
                summary.get('negative_score', 0),
                summary.get('neutral_score', 0)
            ]
        })
        st.bar_chart(chart_data.set_index('æ„Ÿæƒ…'))


def display_comments(comments: list) -> None:
    """Display analyzed comments."""
    st.subheader("ã‚³ãƒ¡ãƒ³ãƒˆä¸€è¦§")

    if not comments:
        st.info("ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # Sentiment filter
    sentiment_filter = st.selectbox(
        "æ„Ÿæƒ…ã§ãƒ•ã‚£ãƒ«ã‚¿",
        ["ã™ã¹ã¦", "ãƒã‚¸ãƒ†ã‚£ãƒ–å„ªå‹¢", "ãƒã‚¬ãƒ†ã‚£ãƒ–å„ªå‹¢", "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å„ªå‹¢"]
    )

    def get_dominant_sentiment(sentiment_scores):
        if not isinstance(sentiment_scores, dict):
            return 'neutral'
        pos = sentiment_scores.get('positive', 0)
        neg = sentiment_scores.get('negative', 0)
        neu = sentiment_scores.get('neutral', 0)
        max_score = max(pos, neg, neu)
        if max_score == pos:
            return 'positive'
        elif max_score == neg:
            return 'negative'
        else:
            return 'neutral'

    filtered_comments = comments
    if sentiment_filter == "ãƒã‚¸ãƒ†ã‚£ãƒ–å„ªå‹¢":
        filtered_comments = [c for c in comments if get_dominant_sentiment(c.get('sentiment')) == 'positive']
    elif sentiment_filter == "ãƒã‚¬ãƒ†ã‚£ãƒ–å„ªå‹¢":
        filtered_comments = [c for c in comments if get_dominant_sentiment(c.get('sentiment')) == 'negative']
    elif sentiment_filter == "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å„ªå‹¢":
        filtered_comments = [c for c in comments if get_dominant_sentiment(c.get('sentiment')) == 'neutral']

    st.write(f"è¡¨ç¤ºä¸­: {len(filtered_comments)}ä»¶ / å…¨{len(comments)}ä»¶")

    # Display comments
    for comment in filtered_comments:
        sentiment_scores = comment.get('sentiment', {})
        if isinstance(sentiment_scores, dict):
            pos = sentiment_scores.get('positive', 0)
            neg = sentiment_scores.get('negative', 0)
            neu = sentiment_scores.get('neutral', 0)

            sentiment_text = f"P:{pos:.2f} N:{neg:.2f} Neu:{neu:.2f}"
        else:
            sentiment_text = "ã‚¹ã‚³ã‚¢ãªã—"

        # ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã®å†’é ­ã‚’æŠ½å‡ºï¼ˆæœ€å¤§50æ–‡å­—ï¼‰
        comment_text = comment.get('text', '')
        preview_text = comment_text[:50] + '...' if len(comment_text) > 50 else comment_text

        with st.expander(
            f"[{sentiment_text}] {preview_text} | {comment.get('author', 'Unknown')} - ğŸ‘ {comment.get('like_count', 0)}"
        ):
            st.write(comment_text)
            
            # Display sentiment scores
            if isinstance(sentiment_scores, dict):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ãƒã‚¸", f"{pos:.4f}")
                with col2:
                    st.metric("ãƒã‚¬", f"{neg:.4f}")
                with col3:
                    st.metric("ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", f"{neu:.4f}")
            
            st.caption(f"æŠ•ç¨¿æ—¥: {comment.get('published_at', 'N/A')}")


def main():
    """Main Streamlit app."""
    st.title("ğŸ“Š YouTube Comment Analyzer")
    st.markdown("YouTubeã®å‹•ç”»IDã¾ãŸã¯URLã‚’å…¥åŠ›ã—ã¦ã€ã‚³ãƒ¡ãƒ³ãƒˆã®æ„Ÿæƒ…åˆ†æã‚’è¡Œã„ã¾ã™ã€‚")

    # Input section
    st.markdown("---")

    user_input = st.text_input(
        "YouTubeå‹•ç”»IDã¾ãŸã¯URL",
        placeholder="ä¾‹: dQw4w9WgXcQ ã¾ãŸã¯ https://www.youtube.com/watch?v=dQw4w9WgXcQ"
    )
    
    # Get comment limit from environment variable
    comment_limit = get_comment_limit()
    st.info(f"ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—æ•°: {comment_limit}ä»¶ (è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§å¤‰æ›´å¯èƒ½)")

    # Extract video ID preview
    if user_input:
        video_id = extract_video_id(user_input)
        if video_id:
            st.success(f"å‹•ç”»ID: `{video_id}`")
        else:
            st.error("æœ‰åŠ¹ãªYouTubeå‹•ç”»IDã¾ãŸã¯URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    # Analyze button
    analyze_button = st.button("åˆ†æé–‹å§‹", type="primary", use_container_width=True)

    # Analysis
    if analyze_button:
        if not user_input:
            st.error("å‹•ç”»IDã¾ãŸã¯URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return

        video_id = extract_video_id(user_input)
        if not video_id:
            st.error("æœ‰åŠ¹ãªYouTubeå‹•ç”»IDã¾ãŸã¯URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return

        with st.spinner(f"å‹•ç”» `{video_id}` ã‚’åˆ†æä¸­..."):
            try:
                result = analyze_video(video_id, comment_limit)

                if result:
                    st.success("åˆ†æå®Œäº†!")

                    # Display results
                    display_video_info(result['video'])
                    st.markdown("---")
                    display_sentiment_summary(result['summary'])
                    st.markdown("---")
                    display_comments(result['comments'])
                else:
                    st.error("å‹•ç”»ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‹•ç”»IDã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

            except QuotaExceededError:
                logger.error("YouTube APIã‚¯ã‚©ãƒ¼ã‚¿è¶…é")
                st.error("YouTube APIã®åˆ©ç”¨ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚æ˜æ—¥å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            except CommentsDisabledError:
                logger.warning("ã‚³ãƒ¡ãƒ³ãƒˆãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
                st.warning("ã“ã®å‹•ç”»ã¯ã‚³ãƒ¡ãƒ³ãƒˆãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            except VideoNotFoundError:
                logger.warning("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                st.error("å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except AuthenticationError:
                logger.error("YouTube APIèªè¨¼ã‚¨ãƒ©ãƒ¼")
                st.error("YouTube APIã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                logger.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    main()
