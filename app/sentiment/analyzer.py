"""Sentiment analysis module using language detection and multi-model inference."""

import logging
import os
import re
import threading

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from langdetect import detect, LangDetectException, DetectorFactory

logger = logging.getLogger(__name__)

# Ensure deterministic language detection
DetectorFactory.seed = 0

# Lock for thread-safe model loading
_model_lock = threading.Lock()

# Check for GPU availability
_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if _device.type == 'cpu':
    torch.set_num_threads(1)  # Single thread for CPU inference

# Japanese model 1: christian-phu (3-class: neg/neu/pos)
_ja_model_1 = None
_ja_tokenizer_1 = None
_ja_id2label_1 = None

# Japanese model 2: kit-nlp (2-class: pos/neg, irony detection)
_ja_model_2 = None
_ja_tokenizer_2 = None
_ja_id2label_2 = None

# Multilingual model (XLM-RoBERTa)
_multi_model = None
_multi_tokenizer = None
_multi_id2label = None

# Model names (configurable via environment variables)
JA_MODEL_1 = os.environ.get('JA_MODEL_1', 'christian-phu/bert-finetuned-japanese-sentiment')  # 3-class
JA_MODEL_2 = os.environ.get('JA_MODEL_2', 'kit-nlp/bert-base-japanese-sentiment-irony')  # 2-class, irony
MULTILINGUAL_MODEL = os.environ.get('MULTILINGUAL_MODEL', 'cardiffnlp/twitter-xlm-roberta-base-sentiment')

# Maximum token length for inference (with validation)
try:
    MAX_LENGTH = int(os.environ.get('MAX_TOKEN_LENGTH', '128'))
    if MAX_LENGTH < 1 or MAX_LENGTH > 512:
        logger.warning(f'MAX_TOKEN_LENGTHãŒç¯„å›²å¤–ã§ã™ ({MAX_LENGTH})ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤128ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚')
        MAX_LENGTH = 128
except (ValueError, TypeError):
    logger.warning('MAX_TOKEN_LENGTHè¨­å®šãŒç„¡åŠ¹ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤128ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚')
    MAX_LENGTH = 128

# Fallback mode: use rules only when all models fail
FALLBACK_TO_RULES_ONLY = os.environ.get('FALLBACK_TO_RULES_ONLY', 'false').lower() == 'true'

# Rule-based dictionaries (module-level constants)
POSITIVE_WORDS = [
    # æ—¥æœ¬èªãƒã‚¸ãƒ†ã‚£ãƒ–
    'æœ€é«˜', 'ç´ æ™´ã‚‰ã—ã„', 'è‰¯ã„', 'ã„ã„', 'ã‚ˆã„', 'å¥½ã', 'å¤§å¥½ã',
    'é¢ç™½ã„', 'ãŠã‚‚ã—ã‚ã„', 'ã‚ªãƒ¢ã‚·ãƒ­ã‚¤', 'æ¥½ã—ã„', 'ãŸã®ã—ã„',
    'æ„Ÿå‹•', 'æ„Ÿæ¿€', 'æ³£ã„ãŸ', 'ã™ã”ã„', 'å‡„ã„', 'ã‚ã‚ŠãŒã¨ã†',
    'ç¥', 'å®Œç’§', 'æœ€å¼·', 'å¤©æ‰', 'ã‚»ãƒ³ã‚¹ã‚ã‚‹',
    'ã‹ã‚ã„ã„', 'å¯æ„›ã„', 'ãã‚Œã„', 'ç¶ºéº—', 'ã‹ã£ã“ã„ã„',
    'ä¸Šæ‰‹', 'ã†ã¾ã„', 'ç¬‘ã£ãŸ', 'çˆ†ç¬‘', 'ã‚¦ã‚±ã‚‹', 'å°Šã„', 'ã‚¨ãƒ¢ã„',
    # è‹±èªãƒã‚¸ãƒ†ã‚£ãƒ–
    'good', 'great', 'nice', 'love', 'amazing', 'awesome', 'best',
    'excellent', 'perfect', 'fantastic', 'wonderful', 'beautiful',
    'cool', 'brilliant', 'impressive', 'incredible',
    # çµµæ–‡å­—
    'ğŸ‘', 'ğŸ˜Š', 'ğŸ˜„', 'â¤', 'ğŸ‰', 'ğŸ‘', 'ğŸ’¯', 'ğŸ˜', 'ğŸ¥°',
    'âœ¨', 'â­', 'ğŸŒŸ', 'ğŸ”¥', 'ğŸ˜', 'ğŸ¤©', 'ğŸ’•', 'ğŸ’–'
]

NEGATIVE_WORDS = [
    # æ—¥æœ¬èªãƒã‚¬ãƒ†ã‚£ãƒ–
    'ã¤ã¾ã‚‰ãªã„', 'ã¤ã¾ã‚“ãªã„', 'ã¤ã¾ã‚‰ã‚“', 'ã²ã©ã„', 'é…·ã„',
    'æ‚ªã„', 'ã‚ã‚‹ã„', 'å«Œã„', 'ãã‚‰ã„', 'æœ€æ‚ª', 'æœ€ä½',
    'ãƒ€ãƒ¡', 'ã ã‚', 'é§„ç›®', 'æ®‹å¿µ', 'ãŒã£ã‹ã‚Š', 'é€€å±ˆ',
    'ã†ã–ã„', 'ã‚¦ã‚¶ã„', 'ã‚¯ã‚½', 'ãã', 'ç³', 'ã‚´ãƒŸ', 'ã”ã¿',
    'ã‚­ãƒ¢ã„', 'ãã‚‚ã„', 'ä¸å¿«', 'èƒ¸ç³', 'ã‚€ã‹ã¤ã', 'ã‚¤ãƒ©ã‚¤ãƒ©',
    'ç„¡ç†', 'ã‚ã‚Šãˆãªã„', 'æ„å‘³ä¸æ˜', 'å¯’ã„', 'ã‚¤ã‚¿ã„', 'ã‚ªãƒ¯ã‚³ãƒ³',
    'ä¸‹æ‰‹', 'ãƒ˜ã‚¿', 'ãƒ‘ã‚¯ãƒª', 'å˜˜', 'ã‚„ã‚‰ã›', 'ã‚¹ãƒ†ãƒ',
    'æ™‚é–“ã®ç„¡é§„', 'ç™»éŒ²è§£é™¤', 'ä½è©•ä¾¡', 'è©æ¬º', 'ç‚ä¸Š',
    # è‹±èªãƒã‚¬ãƒ†ã‚£ãƒ–
    'bad', 'worst', 'hate', 'boring', 'terrible', 'awful',
    'horrible', 'disgusting', 'trash', 'garbage', 'cringe',
    'stupid', 'dumb', 'sucks', 'annoying', 'pathetic',
    # çµµæ–‡å­—
    'ğŸ‘', 'ğŸ˜¢', 'ğŸ˜¡', 'ğŸ’¢', 'ğŸ˜¤', 'ğŸ¤®', 'ğŸ˜’', 'ğŸ’©', 'ğŸ¤¬',
    'ğŸ˜ ', 'ğŸ˜¾', 'ğŸ™„', 'ğŸ˜‘'
]

# Advanced rule patterns for sentiment adjustment (module-level constants for performance)
STRONG_NEGATIVE_PATTERNS = [
    # åŸºæœ¬çš„ãªãƒã‚¬ãƒ†ã‚£ãƒ–è¡¨ç¾
    'ã¤ã¾ã‚‰ãªã„', 'ã¤ã¾ã‚“ãªã„', 'ã¤ã¾ã‚‰ã‚“', 'ãƒã‚¸ã§ã¤ã¾ã‚‰ã‚“', 'ãƒã‚¸ã¤ã¾ã‚‰ã‚“',
    'ã‚¯ãƒƒã‚½ã¤ã¾ã‚‰ã‚“', 'ãã£ãã¤ã¾ã‚‰ã‚“', 'ã¤ã¾ã‚“ã­', 'ã¤ã¾ã‚“ãªã™ã',
    'ã²ã©ã„', 'é…·ã„', 'ãƒ’ãƒ‰ã‚¤', 'ã²ã©éã', 'é…·ã™ã',
    'æœ€æ‚ª', 'ã‚µã‚¤ã‚¢ã‚¯', 'æœ€ä½', 'ã‚µã‚¤ãƒ†ãƒ¼', 'å²ä¸Šæœ€æ‚ª', 'éå»æœ€æ‚ª',
    'ã‚¯ã‚½', 'ãã', 'ç³', 'ã‚¯ãƒƒã‚½', 'ãã£ã', 'ã‚¯ã‚½ã™ã', 'ã‚¯ã‚½éã',
    'ã‚´ãƒŸ', 'ã”ã¿', 'ã‚´ãƒŸã™ã', 'ã‚´ãƒŸå‹•ç”»', 'ã‚´ãƒŸä¼ç”»', 'ã‚´ãƒŸç·¨é›†',
    'ã†ã–ã„', 'ã‚¦ã‚¶ã„', 'ã†ãœãˆ', 'ã‚¦ã‚¼ã‚¨', 'ã‚¦ã‚¶ã™ã', 'ã†ã–ã™ã', 'ã‚¦ã‚¼ãƒ¼',
    'ã‚­ãƒ¢ã„', 'ãã‚‚ã„', 'ã‚­ãƒ¢ã™ã', 'ã‚­ã‚·ãƒ§ã„', 'ãã—ã‚‡ã„', 'æ°—æŒã¡æ‚ªã„', 'ã‚­ãƒ¢',
    'å«Œã„', 'ãã‚‰ã„', 'ã‚­ãƒ©ã‚¤', 'å¤§å«Œã„', 'ã ã„ãã‚‰ã„', 'å«Œã„ã™ã',
    'ä¸å¿«', 'ä¸æ„‰å¿«', 'èƒ¸ç³', 'èƒ¸ã‚¯ã‚½', 'ã‚€ã‹ã¤ã', 'ãƒ ã‚«ã¤ã', 'ã‚¤ãƒ©ã‚¤ãƒ©',
    # YouTubeç‰¹æœ‰ã®è¡¨ç¾
    'æ™‚é–“ã®ç„¡é§„', 'æ™‚é–“è¿”ã›', 'â—‹åˆ†è¿”ã›', 'æ™‚é–“è¿”ã—ã¦', 'äººç”Ÿã®ç„¡é§„',
    'è¦‹ãªãã‚ƒã‚ˆã‹ã£ãŸ', 'è¦‹ã‚‹ã‚“ã˜ã‚ƒãªã‹ã£ãŸ', 'å¾Œæ‚”', 'è¦‹ã¦æã—ãŸ',
    'ç™»éŒ²è§£é™¤', 'ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²è§£é™¤', 'ç™»éŒ²è§£é™¤ã—ã¾ã—ãŸ', 'ã‚¢ãƒ³ãƒç™»éŒ²',
    'ä½è©•ä¾¡', 'ä½è©•ä¾¡æŠ¼ã—ãŸ', 'é€šå ±', 'é€šå ±ã—ã¾ã—ãŸ', 'BAD', 'badæŠ¼ã—ãŸ',
    'ãŒã£ã‹ã‚Š', 'ã‚¬ãƒƒã‚«ãƒª', 'æœŸå¾…å¤–ã‚Œ', 'æœŸå¾…ã¯ãšã‚Œ', 'æœŸå¾…è£åˆ‡ã‚‰ã‚ŒãŸ',
    'è©æ¬º', 'ã‚µãƒ ãƒè©æ¬º', 'ã‚¿ã‚¤ãƒˆãƒ«è©æ¬º', 'é‡£ã‚Š', 'é‡£ã‚Šã‚¿ã‚¤ãƒˆãƒ«', 'é‡£ã‚Šã‚µãƒ ãƒ',
    'ã‚„ã‚ã¦', 'ã‚„ã‚ã‚', 'ã‚„ã‚ã¡ã¾ãˆ', 'å¸°ã‚Œ', 'æ¶ˆãˆã‚', 'å¼•é€€ã—ã‚', 'è¾ã‚ã‚',
    'ç‚ä¸Š', 'å•é¡Œ', 'ç‚ä¸Šæ¡ˆä»¶', 'ã‚¢ã‚¦ãƒˆ', 'ã‚„ã°ã„', 'ãƒ¤ãƒã„', 'ãƒ¤ãƒã‚¤', 'ã‚„ã°ã™ã',
    'ã‚ªãƒ¯ã‚³ãƒ³', 'ã‚ªãƒ¯ã‚³ãƒ³åŒ–', 'çµ‚ã‚ã£ãŸ', 'çµ‚ã‚ã£ã¦ã‚‹', 'åŠ£åŒ–', 'åŠ£åŒ–ã—ãŸ',
    # æ„Ÿæƒ…è¡¨ç¾
    'è…¹ç«‹ã¤', 'ã‚¤ãƒ©ã¤ã', 'ãƒ ã‚«ã¤ã', 'ã†ã‚“ã–ã‚Š', 'ã‚¦ãƒ³ã‚¶ãƒª', 'ã—ã‚“ã©ã„',
    'ç„¡ç†', 'ãƒ ãƒª', 'ã‚ã‚Šãˆãªã„', 'ã‚ã‚Šå¾—ãªã„', 'æ„å‘³ä¸æ˜', 'ç†è§£ä¸èƒ½',
    'å¯’ã„', 'ã•ã‚€ã„', 'ã‚µãƒ ã„', 'ç—›ã„', 'ã‚¤ã‚¿ã„', 'æ¥ãšã‹ã—ã„', 'æ¥ãšã„',
    'è¦‹ã‚‹ã«å ªãˆãªã„', 'è¦‹ã¦ã‚‰ã‚Œãªã„', 'èã„ã¦ã‚‰ã‚Œãªã„', 'è€ãˆã‚‰ã‚Œãªã„',
    # æ‰¹åˆ¤è¡¨ç¾
    'ãƒ€ãƒ¡', 'ã ã‚', 'é§„ç›®', 'ãƒ€ãƒ¡ãƒ€ãƒ¡', 'ã ã‚ã ã‚', 'ãƒ€ãƒ¡ã™ã',
    'ä¸‹æ‰‹', 'ãƒ˜ã‚¿', 'ã¸ãŸ', 'ä¸‹æ‰‹ãã', 'ã¸ãŸãã', 'ä¸‹æ‰‹ã™ã',
    'é›‘', 'é©å½“', 'ãƒ†ã‚­ãƒˆãƒ¼', 'ã„ã„åŠ æ¸›', 'ãšã•ã‚“',
    'ãƒ‘ã‚¯ãƒª', 'ã±ãã‚Š', 'ãƒ‘ã‚¯ã£ãŸ', 'ã‚³ãƒ”ãƒ¼', 'äºŒç•ªç…ã˜', 'åŠ£åŒ–ã‚³ãƒ”ãƒ¼',
    'å˜˜', 'ã†ã', 'ã‚¦ã‚½', 'å˜˜ã¤ã', 'ãƒ‡ãƒ', 'ã‚„ã‚‰ã›', 'ãƒ¤ãƒ©ã‚»', 'ã‚¹ãƒ†ãƒ',
    # æ”»æ’ƒçš„è¡¨ç¾
    'æ­»ã­', 'ããŸã°ã‚Œ', 'æ®ºã™', 'æ®ºã—ãŸã„', 'ã€‡ã­', 'ã—ã­', 'ã‚¿ãƒ’ã­',
    'ã‚¢ãƒ›', 'ã‚ã»', 'ãƒã‚«', 'ã°ã‹', 'ã‚¬ã‚¤ã‚¸', 'ã‚«ã‚¹', 'ã‹ã™', 'ã‚¯ã‚º', 'ããš',
    'éšœå®³', 'ã—ã‚‡ã†ãŒã„', 'ã‚²ã‚§ã‚¸', 'ã‚´ãƒŸã‚¯ã‚º',
    # æ›–æ˜§ãƒ»å¾®å¦™ãªãƒã‚¬ãƒ†ã‚£ãƒ–
    'å¾®å¦™', 'ã³ã¿ã‚‡ã†', 'ãƒ“ãƒŸãƒ§ãƒ¼', 'å¾®å¦™ã™ã',
    'ãªã‚“ã‹é•ã†', 'ã‚³ãƒ¬ã‚¸ãƒ£ãƒŠã‚¤', 'ã“ã‚Œã˜ã‚ƒãªã„',
    # çš®è‚‰ãƒ»å†·ç¬‘
    'è‰ç”Ÿãˆã‚‹', 'è‰ã‚‚ç”Ÿãˆãªã„', 'è‰æ¯ã‚Œã‚‹',
    'ã¯ï¼Ÿ', 'ã¯ãï¼Ÿ', 'ãˆï¼Ÿ', 'ãˆã‡...', 'ã†ãƒ¼ã‚“',
    'ãªã«ã“ã‚Œ', 'ä½•ã“ã‚Œ', 'ãªã‚“ã ã“ã‚Œ',
    # YouTubeæ‰¹åˆ¤
    'è¦‹ã‚‹ä¾¡å€¤ãªã—', 'æ™‚é–“æ³¥æ£’', 'é‡‘è¿”ã›',
    'æ¡ˆä»¶', 'æ¡ˆä»¶è‡­', 'PRè‡­', 'å®£ä¼è‡­',
    'å†ç”Ÿæ•°ç¨¼ã', 'é‡‘å„²ã‘', 'åç›ŠåŒ–',
    # é£½ããƒ»ãƒãƒ³ãƒãƒª
    'é£½ããŸ', 'ã‚ããŸ', 'é£½ãã¦ããŸ',
    'å†·ã‚ãŸ', 'ã•ã‚ãŸ', 'å†·ã‚ã‚‹',
    'æ»‘ã£ã¦ã‚‹', 'ã‚¹ãƒ™ã£ã¦ã‚‹', 'ã™ã¹ã£ã¦ã‚‹', 'æ»‘ã‚Šæ•£ã‚‰ã‹ã—',
    'ãƒ¯ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³', 'ãƒãƒ³ãƒãƒª', 'ã„ã¤ã‚‚ã¨åŒã˜',
    'æ‰‹æŠœã', 'æ‰‹ã¬ã', 'ã‚„ã£ã¤ã‘',
    'ã‚„ã‚‹æ°—ãªã„', 'ã‚„ã‚‹æ°—ãªã•ã™ã', 'ã‚„ã‚‹æ°—æ„Ÿã˜ãªã„',
    # è‹±èªè¡¨ç¾
    'bad', 'worst', 'terrible', 'awful', 'horrible', 'disgusting', 'hate',
    'waste of time', 'garbage', 'trash', 'cringe', 'cringey', 'creepy',
    'boring', 'stupid', 'dumb', 'sucks', 'shit', 'bullshit',
    'pathetic', 'lame', 'annoying', 'irritating', 'disappointing',
    'dislike', 'unsubscribed', 'clickbait', 'fake', 'scam',
    'meh', 'mediocre', 'overrated', 'overhyped',
    # çµµæ–‡å­—
    'ğŸ‘', 'ğŸ˜¡', 'ğŸ’¢', 'ğŸ˜¤', 'ğŸ¤®', 'ğŸ˜’', 'ğŸ’©', 'ğŸ¤¬', 'ğŸ˜ ', 'ğŸ˜¾',
    'ğŸ™„', 'ğŸ˜‘', 'ğŸ˜', 'ğŸ˜“', 'ğŸ˜°', 'ğŸ˜¨', 'ğŸ˜±', 'ğŸ¤¯', 'ğŸ˜©', 'ğŸ˜«'
]

SARCASM_PATTERNS = [
    # æ£’èª­ã¿ãƒ»çš®è‚‰ãƒãƒ¼ã‚«ãƒ¼
    r'ã•ã™ãŒ.*[ï¼ˆ(]æ£’[)ï¼‰]', r'ã™ã”ã„.*[ï¼ˆ(]æ£’[)ï¼‰]', r'ç´ æ™´ã‚‰ã—ã„.*[ï¼ˆ(]æ£’[)ï¼‰]',
    r'[ï¼ˆ(]æ£’[)ï¼‰]', r'[ï¼ˆ(]æ£’èª­ã¿[)ï¼‰]', r'[ï¼ˆ(]ç™½ç›®[)ï¼‰]',
    r'[ï¼ˆ(]å¤±ç¬‘[)ï¼‰]', r'[ï¼ˆ(]è‹¦ç¬‘[)ï¼‰]', r'[ï¼ˆ(]å‘†ã‚Œ[)ï¼‰]', r'[ï¼ˆ(]ã‚ãã‚Œ[)ï¼‰]',
    r'[ï¼ˆ(]ç¬‘[)ï¼‰](?!.*www)', r'[ï¼ˆ(]çˆ†ç¬‘[)ï¼‰](?!.*www)',
    r'[ï¼ˆ(]çœŸé¡”[)ï¼‰]', r'[ï¼ˆ(]é ã„ç›®[)ï¼‰]', r'[ï¼ˆ(]ç›®ãŒæ­»ã‚“ã§ã‚‹[)ï¼‰]',
    # å©‰æ›²è¡¨ç¾
    'ã•ã™ãŒã§ã™ã­', 'ã™ã”ã„ã§ã™ã­', 'ã„ã„ã§ã™ã­', 'ç´ æ™´ã‚‰ã—ã„ã§ã™ã­',
    'ãã†ã§ã™ã­', 'ãã†ãªã‚“ã ', 'ã¸ãˆãƒ¼', 'ãµãƒ¼ã‚“', 'ã¸ãƒ¼', 'ã»ãƒ¼',
    'ãªã‚‹ã»ã©', 'ãªã‚‹ã»ã©ã­', 'ãã£ã‹ãƒ¼', 'ãã†ã‹ãƒ¼',
    'åˆ†ã‹ã‚Šã¾ã—ãŸ', 'ã‚ã‹ã‚Šã¾ã—ãŸ', 'ç†è§£ã—ã¾ã—ãŸ',
    # éå‰°ãªè¤’ã‚è¨€è‘‰ï¼ˆçš®è‚‰ã¨ã—ã¦æ©Ÿèƒ½ï¼‰
    r'æœ€é«˜ã§ã™ã­[!ï¼]{2,}', r'ç¥[!ï¼]{3,}', r'å®Œç’§[!ï¼]{3,}',
    r'ã•ã™ãŒ[!ï¼]{2,}', r'ã™ã°ã‚‰ã—ã„[!ï¼]{3,}',
    # æ˜ç¢ºãªçš®è‚‰è¡¨ç¾
    'ã•ã™ãŒã ã‚', 'ãŠè¦‹äº‹', 'æµçŸ³ã ã‚', 'å‚ã‚Šã¾ã—ãŸ', 'é™å‚',
    'ã‚„ã‚Šã¾ã™ã­', 'ã‚„ã‚‹ãªã‚', 'ç›¸å¤‰ã‚ã‚‰ãš', 'ã„ã¤ã‚‚é€šã‚Š',
    'äºˆæƒ³é€šã‚Š', 'æƒ³å®šå†…', 'æœŸå¾…ã‚’è£åˆ‡ã‚‰ãªã„'
]

RHETORICAL_PATTERNS = [
    # ã€Œã“ã‚ŒãŒã€œï¼Ÿã€å‹
    r'ã“ã‚ŒãŒ.*[?ï¼Ÿ]', r'ã“ã®.*ãŒ.*[?ï¼Ÿ]', r'ã“ã‚“ãªã®.*[?ï¼Ÿ]',
    # ã€Œä½•ãŒã€œï¼Ÿã€å‹
    r'ä½•ãŒ.*[?ï¼Ÿ]', r'ã©ã“ãŒ.*[?ï¼Ÿ]', r'èª°ãŒ.*[?ï¼Ÿ]', r'ã„ã¤.*[?ï¼Ÿ]',
    # ã€Œã©ã†ã—ã¦ã€œï¼Ÿã€å‹
    r'ã©ã†ã—ã¦.*[?ï¼Ÿ]', r'ãªãœ.*[?ï¼Ÿ]', r'ãªã‚“ã§.*[?ï¼Ÿ]',
    # å…·ä½“çš„ãªåèª
    'ã“ã‚ŒãŒé¢ç™½ã„ã®', 'ã“ã‚ŒãŒé¢ç™½ã„ï¼Ÿ', 'ã“ã‚ŒãŒé¢ç™½ã„ã®ï¼Ÿ', 'ã“ã‚Œé¢ç™½ã„ï¼Ÿ',
    'ã“ã‚ŒãŒã„ã„ã®', 'ã“ã‚ŒãŒã„ã„ã®ï¼Ÿ', 'ã“ã‚ŒãŒè‰¯ã„ã®ï¼Ÿ', 'ã“ã‚Œè‰¯ã„ï¼Ÿ',
    'ä½•ãŒè‰¯ã„ã®', 'ä½•ãŒã„ã„ã®', 'ä½•ãŒé¢ç™½ã„ã®', 'ä½•ãŒãŠã‚‚ã—ã‚ã„ã®',
    'ã©ã“ãŒé¢ç™½ã„', 'ã©ã“ãŒã„ã„', 'ã©ã“ãŒè‰¯ã„', 'ã©ã“ãŒã™ã”ã„',
    'ã©ã“ãŒç¥', 'ä½•ãŒç¥', 'ã“ã‚ŒãŒç¥', 'ã©ã“ãŒæœ€é«˜', 'ä½•ãŒæœ€é«˜',
    'ã©ã“ãŒã‹ã‚ã„ã„', 'ä½•ãŒã‹ã‚ã„ã„', 'ã©ã“ãŒã„ã„ã®',
    'èª°ãŒè¦‹ã‚‹ã®', 'èª°å¾—', 'éœ€è¦ã‚ã‚‹ï¼Ÿ', 'éœ€è¦ã‚ã‚‹ã®ï¼Ÿ',
    'ãƒã‚¸ã§è¨€ã£ã¦ã‚‹ï¼Ÿ', 'ã¾ã˜ã§è¨€ã£ã¦ã‚‹ï¼Ÿ', 'æœ¬æ°—ã§è¨€ã£ã¦ã‚‹ï¼Ÿ',
    'æ­£æ°—ã‹ï¼Ÿ', 'æ­£æ°—ï¼Ÿ', 'å†—è«‡ã ã‚ˆã­ï¼Ÿ', 'ãƒã‚¿ã ã‚ˆã­ï¼Ÿ',
    # è‹±èªã®åèª
    'really?', 'seriously?', 'are you serious?', 'is this good?',
    'you serious?', 'for real?', 'are you kidding?',
    'what is this?', 'what the hell?', 'why?'
]

STRONG_POSITIVE_PATTERNS = [
    # æœ€ä¸Šç´šã®è¤’ã‚è¨€è‘‰
    'æœ€é«˜', 'ã‚µã‚¤ã‚³ãƒ¼', 'æœ€é«˜ã™ã', 'æœ€é«˜éã', 'å²ä¸Šæœ€é«˜', 'éå»æœ€é«˜',
    'ç¥', 'ç¥å›', 'ç¥å‹•ç”»', 'ç¥ç·¨é›†', 'ç¥ä¼ç”»', 'ç¥ã™ã', 'ç¥ã£ã¦ã‚‹',
    'å®Œç’§', 'ãƒ‘ãƒ¼ãƒ•ã‚§ã‚¯ãƒˆ', 'å®Œç’§ã™ã', 'å®Œãºã',
    'ç´ æ™´ã‚‰ã—ã„', 'ã™ã°ã‚‰ã—ã„', 'ç´ æ™´ã‚‰ã—ã™ã', 'ç´ æ•µ', 'ã‚¹ãƒ†ã‚­', 'ã™ã¦ã',
    'æœ€å¼·', 'ã‚µã‚¤ã‚­ãƒ§ãƒ¼', 'æœ€å¼·ã™ã', 'ç„¡æ•µ', 'ãƒ ãƒ†ã‚­',
    # æ„Ÿæƒ…è¡¨ç¾
    'æ„Ÿå‹•', 'æ„Ÿå‹•ã—ãŸ', 'æ„Ÿå‹•çš„', 'æ³£ã„ãŸ', 'æ³£ã‘ã‚‹', 'æ¶™ãŒå‡ºãŸ', 'æ¶™å‡ºãŸ',
    'æ„Ÿæ¿€', 'ã˜ãƒ¼ã‚“', 'ã‚¸ãƒ¼ãƒ³', 'ã‚°ãƒƒã¨ããŸ', 'ãã£ã¨ããŸ',
    'ç¬‘ã£ãŸ', 'çˆ†ç¬‘', 'ãƒ¯ãƒ­ã‚¿', 'ã‚ã‚ãŸ', 'ã‚¦ã‚±ã‚‹', 'ã†ã‘ã‚‹', 'é¢ç™½ã™ã',
    'æ¥½ã—ã„', 'ãŸã®ã—ã„', 'ã‚¿ãƒã‚·ã‚¤', 'æ¥½ã—ã™ã', 'æ¥½ã—ã‹ã£ãŸ', 'æ¥½ã—ã‚ãŸ',
    'ã™ã”ã„', 'å‡„ã„', 'ã‚¹ã‚´ã„', 'ã™ã”ã™ã', 'å‡„ã™ã', 'ã‚¹ã‚´ã™ã', 'ã‚„ã°ã„',
    # å¥½æ„è¡¨ç¾
    'å¥½ã', 'ã™ã', 'ã‚¹ã‚­', 'å¤§å¥½ã', 'ã ã„ã™ã', 'ãƒ€ã‚¤ã‚¹ã‚­', 'å¥½ãã™ã',
    'æ„›ã—ã¦ã‚‹', 'å¤§å¥½ç‰©', 'æ¨ã›ã‚‹', 'æ¨ã›ã¾ã™', 'ç¥æ¨ã—',
    'ã‚ã‚ŠãŒã¨ã†', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™', 'ã‚µãƒ³ã‚­ãƒ¥ãƒ¼', 'thx', 'thanks',
    'å°Šã„', 'ã¨ã†ã¨ã„', 'ãŸã¾ã‚‰ã‚“', 'ãŸã¾ã‚‰ãªã„', 'ã‚¨ãƒ¢ã„', 'ãˆã‚‚ã„',
    # å“è³ªè©•ä¾¡
    'é¢ç™½ã„', 'ãŠã‚‚ã—ã‚ã„', 'ã‚ªãƒ¢ã‚·ãƒ­ã‚¤', 'é¢ç™½ã™ã', 'è¶…é¢ç™½ã„', 'ã‚ã£ã¡ã‚ƒé¢ç™½ã„',
    'ã‹ã‚ã„ã„', 'å¯æ„›ã„', 'ã‚«ãƒ¯ã‚¤ã‚¤', 'å¯æ„›ã™ã', 'ã‹ã‚ã„ã™ã', 'ã‹ã‚ã‚†ã„',
    'ãã‚Œã„', 'ç¶ºéº—', 'ã‚­ãƒ¬ã‚¤', 'ç¾ã—ã„', 'ã†ã¤ãã—ã„', 'ç¾äºº', 'å¯æ†',
    'ã‹ã£ã“ã„ã„', 'ã‚«ãƒƒã‚³ã„ã„', 'ã‚¤ã‚±ãƒ¡ãƒ³', 'ã‹ã£ã“ã‚ˆã™ã',
    'ã„ã„', 'è‰¯ã„', 'ã‚ˆã„', 'ã„ã„ã­', 'è‰¯ã„ã­', 'è‰¯ã™ã', 'ã‚ã£ã¡ã‚ƒã„ã„',
    'ã™ã”ãã„ã„', 'è¶…ã„ã„', 'ã‚ã¡ã‚ƒã„ã„', 'ã‚ã¡ã‚ƒãã¡ã‚ƒã„ã„', 'ãƒ¡ãƒãƒ£ã„ã„',
    # å¼·èª¿è¡¨ç¾
    'ç¥å›', 'ç¥ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'åä½œ', 'å‚‘ä½œ', 'åŠ›ä½œ', 'ç§€ä½œ', 'è‰¯ä½œ',
    'å¤©æ‰', 'å¤©æ‰çš„', 'ã™ã°ã‚‰ã—ã™ãã‚‹', 'ã‚„ã°ã™ãã‚‹',
    'æœ€é«˜å³°', 'ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«', 'ãƒã‚¤ãƒ¬ãƒ™ãƒ«', 'ã‚¯ã‚ªãƒªãƒ†ã‚£é«˜ã„',
    # è³è³›è¡¨ç¾
    'ä¸Šæ‰‹', 'ã†ã¾ã„', 'ã‚¦ãƒã„', 'ä¸Šæ‰‹ã„', 'ä¸Šæ‰‹ã™ã', 'ã†ã¾ã™ã',
    'å¤©æ‰', 'ã¦ã‚“ã•ã„', 'ã‚»ãƒ³ã‚¹ã‚ã‚‹', 'ã‚»ãƒ³ã‚¹ã„ã„', 'ã‚»ãƒ³ã‚¹æŠœç¾¤',
    'ãƒ—ãƒ­', 'ãƒ—ãƒ­ç´š', 'ãƒ—ãƒ­ãƒ¬ãƒ™ãƒ«', 'ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«',
    'è·äºº', 'è·äººæŠ€', 'åŒ ', 'æŠ€è¡“ãŒã™ã”ã„', 'æŠ€è¡“åŠ›é«˜ã„',
    # å¿œæ´è¡¨ç¾
    'å¿œæ´', 'å¿œæ´ã—ã¦ã‚‹', 'é ‘å¼µã‚Œ', 'ãŒã‚“ã°ã‚Œ', 'ãƒ•ã‚¡ã‚¤ãƒˆ', 'ã‚¬ãƒ³ãƒ',
    'æœŸå¾…', 'æœŸå¾…ã—ã¦ã‚‹', 'æ¥½ã—ã¿', 'æ¥½ã—ã¿ã«ã—ã¦ã‚‹', 'å¾…ã£ã¦ãŸ', 'ãšã£ã¨å¾…ã£ã¦ãŸ',
    'å¾…ã£ã¦ã¾ã—ãŸ', 'ã¾ã£ã¦ã¾ã—ãŸ', 'å¾…æœ›',
    'ã‚‚ã£ã¨è¦‹ãŸã„', 'ã¾ãŸè¦‹ãŸã„', 'ãƒªãƒ”ãƒ¼ãƒˆ', 'ãƒªãƒ”ã—ã¦ã‚‹', 'ä½•åº¦ã‚‚è¦‹ãŸ',
    'æ¯æ—¥è¦‹ã¦ã‚‹', 'æ¯å›è¦‹ã¦ã‚‹', 'ãƒ˜ãƒ“ãƒ­ãƒ†',
    'ç™»éŒ²ã—ãŸ', 'ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ã—ãŸ', 'é«˜è©•ä¾¡', 'é«˜è©•ä¾¡ã—ãŸ', 'ã„ã„ã­æŠ¼ã—ãŸ',
    'ã‚°ãƒƒãƒ‰ãƒœã‚¿ãƒ³', 'ã‚°ãƒƒãƒ‰', 'GOOD', 'good',
    # å…±æ„Ÿãƒ»ç†è§£
    'å…±æ„Ÿ', 'ã‚ã‹ã‚‹', 'ã‚ã‹ã‚Šã¿', 'ã‚ã‹ã‚Šã¿ãŒæ·±ã„',
    'ãã‚Œãª', 'ã»ã‚“ã¨ãã‚Œ', 'ã“ã‚Œ', 'ã“ã‚Œãª', 'ã¾ã•ã«ã“ã‚Œ',
    'åŒæ„', 'æ¿€ã—ãåŒæ„', 'ç¦¿åŒ',
    # ç™’ã—ãƒ»å…ƒæ°—
    'ç™’ã•ã‚Œã‚‹', 'ç™’ã—', 'ç™’ã•ã‚ŒãŸ', 'ã»ã£ã“ã‚Š',
    'å…ƒæ°—å‡ºãŸ', 'å…ƒæ°—ã‚‚ã‚‰ã£ãŸ', 'å…ƒæ°—ã«ãªã£ãŸ', 'åŠ±ã¾ã•ã‚ŒãŸ',
    'å‹‡æ°—ã‚‚ã‚‰ã£ãŸ', 'ãƒ‘ãƒ¯ãƒ¼ã‚‚ã‚‰ã£ãŸ',
    # å­¦ã³
    'å‹‰å¼·ã«ãªã‚‹', 'å‚è€ƒã«ãªã‚‹', 'ãŸã‚ã«ãªã‚‹', 'åŠ©ã‹ã‚‹', 'åŠ©ã‹ã£ãŸ',
    # ä¸­æ¯’æ€§
    'ä¸­æ¯’', 'ä¸­æ¯’æ€§', 'ä¸­æ¯’ã«ãªã‚‹', 'ãƒãƒã‚‹', 'ã¯ã¾ã‚‹', 'ãƒãƒã£ãŸ',
    'æ²¼', 'æ²¼è½ã¡', 'æŠœã‘å‡ºã›ãªã„',
    # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ„Ÿå˜†
    'ã‚„ã£ãŸ', 'ã‚ˆã—', 'ã„ã„ã', 'ãƒŠã‚¤ã‚¹', 'ã‚°ãƒƒãƒ‰', 'ã‚°ãƒ¬ãƒ¼ãƒˆ',
    'ã‚ãƒ¼ã„', 'ã‚„ã£ãŸãƒ¼', 'ã‚ˆã£ã—ã‚ƒ', 'ããŸãƒ¼', 'ã‚­ã‚¿ãƒ¼', 'ã‚­ã‚¿â”',
    # è‹±èªè¡¨ç¾
    'amazing', 'awesome', 'excellent', 'perfect', 'fantastic', 'wonderful',
    'great', 'good', 'nice', 'beautiful', 'gorgeous', 'stunning',
    'love', 'loved', 'loved it', 'brilliant', 'magnificent', 'outstanding',
    'impressive', 'incredible', 'unbelievable', 'mindblowing', 'epic',
    'cool', 'dope', 'fire', 'lit', 'best', 'masterpiece',
    # çµµæ–‡å­—
    'â¤', 'ğŸ’•', 'ğŸ’–', 'ğŸ’—', 'ğŸ’“', 'ğŸ’', 'ğŸ’˜', 'ğŸ˜', 'ğŸ¥°', 'ğŸ˜Š',
    'ğŸ˜„', 'ğŸ˜', 'ğŸ¤£', 'ğŸ˜‚', 'ğŸ‰', 'ğŸŠ', 'ğŸ‘', 'ğŸ‘', 'ğŸ’¯', 'âœ¨',
    'â­', 'ğŸŒŸ', 'ğŸ’«', 'ğŸ”¥', 'ğŸ˜', 'ğŸ¤©', 'ğŸ˜ƒ', 'ğŸ˜†', 'ğŸ™Œ', 'ğŸ‘Œ'
]

NEGATION_PATTERNS = [
    # æ—¥æœ¬èªå¦å®š
    'ãªã„', 'ãªã‹ã£ãŸ', 'ãªãã¦', 'ãªã„ãª', 'ãªã„ã­', 'ãªã„ã‚',
    'ã¾ã›ã‚“', 'ã¾ã›ã‚“ã§ã—ãŸ', 'ã¬', 'ã‚“', 'ãš', 'ã‚“ã ',
    # è‹±èªå¦å®š
    'not', 'no', 'never', 'nothing', "don't", "doesn't",
    "didn't", "won't", "can't", "couldn't", "shouldn't"
]


def load_models() -> None:
    """Load sentiment analysis models (called only once at startup, thread-safe)."""
    global _ja_model_1, _ja_tokenizer_1, _ja_id2label_1
    global _ja_model_2, _ja_tokenizer_2, _ja_id2label_2
    global _multi_model, _multi_tokenizer, _multi_id2label

    # Quick check without lock (double-checked locking pattern)
    if _ja_model_1 is not None and _ja_model_2 is not None and _multi_model is not None:
        return  # Already loaded

    with _model_lock:
        # Check again inside lock to prevent race condition
        if _ja_model_1 is not None and _ja_model_2 is not None and _multi_model is not None:
            return  # Already loaded by another thread

        # Load Japanese model 1 (christian-phu: 3-class)
        try:
            logger.info(f'æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«1ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {JA_MODEL_1}')
            _ja_tokenizer_1 = AutoTokenizer.from_pretrained(JA_MODEL_1)
            _ja_model_1 = AutoModelForSequenceClassification.from_pretrained(JA_MODEL_1)
            _ja_model_1.to(_device)
            _ja_model_1.eval()
            _ja_id2label_1 = _ja_model_1.config.id2label if hasattr(_ja_model_1.config, 'id2label') else {0: 'negative', 1: 'neutral', 2: 'positive'}
            logger.info(f'æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«1ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸ (labels: {_ja_id2label_1})')
        except Exception as e:
            logger.error(f'æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«1ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}')
            _ja_model_1 = None
            _ja_tokenizer_1 = None

        # Load Japanese model 2 (kit-nlp: 2-class, irony detection)
        try:
            logger.info(f'æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«2ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {JA_MODEL_2}')
            _ja_tokenizer_2 = AutoTokenizer.from_pretrained(JA_MODEL_2)
            _ja_model_2 = AutoModelForSequenceClassification.from_pretrained(JA_MODEL_2)
            _ja_model_2.to(_device)
            _ja_model_2.eval()
            _ja_id2label_2 = _ja_model_2.config.id2label if hasattr(_ja_model_2.config, 'id2label') else {0: 'ãƒã‚¸ãƒ†ã‚£ãƒ–', 1: 'ãƒã‚¬ãƒ†ã‚£ãƒ–'}
            logger.info(f'æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«2ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸ (labels: {_ja_id2label_2})')
        except Exception as e:
            logger.error(f'æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«2ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}')
            _ja_model_2 = None
            _ja_tokenizer_2 = None

        # Load multilingual model
        try:
            logger.info(f'å¤šè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {MULTILINGUAL_MODEL}')
            _multi_tokenizer = AutoTokenizer.from_pretrained(MULTILINGUAL_MODEL)
            _multi_model = AutoModelForSequenceClassification.from_pretrained(MULTILINGUAL_MODEL)
            _multi_model.to(_device)
            _multi_model.eval()
            _multi_id2label = _multi_model.config.id2label if hasattr(_multi_model.config, 'id2label') else {0: 'negative', 1: 'neutral', 2: 'positive'}
            logger.info(f'å¤šè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸ (labels: {_multi_id2label})')
        except Exception as e:
            logger.error(f'å¤šè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}')
            _multi_model = None
            _multi_tokenizer = None


def _detect_language(text: str) -> str:
    """
    Detect language of text using character-based heuristics and langdetect.

    Args:
        text: Input text

    Returns:
        Language code ('ja' for Japanese, 'other' for others)
    """
    # Check for Japanese characters first (more reliable for short texts)
    # Hiragana: \u3040-\u309F, Katakana: \u30A0-\u30FF, Kanji: \u4E00-\u9FFF
    japanese_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]')
    if japanese_pattern.search(text):
        return 'ja'

    # For texts without Japanese characters, use langdetect
    try:
        lang_code = detect(text)
        return 'ja' if lang_code == 'ja' else 'other'
    except LangDetectException as e:
        logger.warning(f'è¨€èªåˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}')
        # Default to multilingual model for ambiguous cases
        return 'other'


def _preprocess_text(text: str) -> str:
    """Preprocess text for classification."""
    # Remove URLs
    text = re.sub(r'https?://\S+', '', text)
    # Remove HTML tags
    text = re.sub(r'<[^>]+>', '', text)
    # Normalize whitespace
    text = ' '.join(text.split())
    return text.strip()


def _rule_based_classify(text: str) -> str:
    """Simple rule-based sentiment classification (binary: pos/neg)."""

    text_lower = text.lower()

    pos_count = sum(1 for word in POSITIVE_WORDS if word in text_lower or word in text)
    neg_count = sum(1 for word in NEGATIVE_WORDS if word in text_lower or word in text)

    # Binary classification: always return pos or neg
    if pos_count >= neg_count:
        return 'pos'
    else:
        return 'neg'


def _adjust_sentiment_with_rules(text: str, scores: dict) -> dict:
    """
    Apply advanced rule-based correction to sentiment scores.
    Detects YouTube-specific expressions including sarcasm, irony, and rhetorical questions.

    Args:
        text: Original text
        scores: Model prediction scores {"positive": float, "negative": float, "neutral": float}

    Returns:
        dict: Corrected scores with accumulated adjustments (max 0.4)
    """
    text_lower = text.lower()

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«å®šæ•°ã‚’ä½¿ç”¨ï¼‰
    neg_match_count = sum(1 for pattern in STRONG_NEGATIVE_PATTERNS if pattern in text_lower or pattern in text)
    pos_match_count = sum(1 for pattern in STRONG_POSITIVE_PATTERNS if pattern in text_lower or pattern in text)

    # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    sarcasm_match = any(re.search(pattern, text) for pattern in SARCASM_PATTERNS)
    rhetorical_match = any(re.search(pattern, text) for pattern in RHETORICAL_PATTERNS)

    # å¦å®šè¡¨ç¾ã®æ¤œå‡º
    has_negation = any(pattern in text_lower for pattern in NEGATION_PATTERNS)

    # ã‚¹ã‚³ã‚¢è£œæ­£å€¤ã®åˆæœŸåŒ–
    positive_adjustment = 0.0
    negative_adjustment = 0.0
    neutral_adjustment = 0.0

    corrections_applied = []

    # 1. å¼·ã„ãƒã‚¬ãƒ†ã‚£ãƒ–è¡¨ç¾ã®è£œæ­£
    if neg_match_count >= 2:
        negative_adjustment += 0.25
        positive_adjustment -= 0.25
        corrections_applied.append(f'å¼·ãƒã‚¬è¡¨ç¾x{neg_match_count}')
    elif neg_match_count >= 1:
        negative_adjustment += 0.15
        positive_adjustment -= 0.15
        corrections_applied.append(f'ãƒã‚¬è¡¨ç¾x{neg_match_count}')

    # 2. çš®è‚‰è¡¨ç¾ã®è£œæ­£
    if sarcasm_match:
        negative_adjustment += 0.2
        positive_adjustment -= 0.2
        corrections_applied.append('çš®è‚‰æ¤œå‡º')

    # 3. åèªè¡¨ç¾ã®è£œæ­£
    if rhetorical_match:
        negative_adjustment += 0.2
        positive_adjustment -= 0.2
        corrections_applied.append('åèªæ¤œå‡º')

    # 4. ãƒã‚¸ãƒ†ã‚£ãƒ–+å¦å®š = ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼ˆä¾‹: é¢ç™½ããªã„ï¼‰
    if pos_match_count >= 1 and has_negation:
        negative_adjustment += 0.2
        positive_adjustment -= 0.2
        corrections_applied.append('ãƒã‚¸+å¦å®š')
    # 5. ãƒã‚¸ãƒ†ã‚£ãƒ–è¡¨ç¾ã®è£œæ­£ï¼ˆå¦å®šãŒãªã„å ´åˆã®ã¿ï¼‰
    elif pos_match_count >= 2 and not has_negation:
        positive_adjustment += 0.25
        negative_adjustment -= 0.25
        corrections_applied.append(f'å¼·ãƒã‚¸è¡¨ç¾x{pos_match_count}')
    elif pos_match_count >= 1 and not has_negation:
        positive_adjustment += 0.15
        negative_adjustment -= 0.15
        corrections_applied.append(f'ãƒã‚¸è¡¨ç¾x{pos_match_count}')

    # è£œæ­£å€¤ã‚’æœ€å¤§0.3ã«åˆ¶é™ï¼ˆ3ã‚¯ãƒ©ã‚¹ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰
    negative_adjustment = max(min(negative_adjustment, 0.3), -0.3)
    positive_adjustment = max(min(positive_adjustment, 0.3), -0.3)

    # ã‚¹ã‚³ã‚¢ã«è£œæ­£ã‚’é©ç”¨
    corrected = scores.copy()
    corrected['negative'] = max(min(corrected['negative'] + negative_adjustment, 1.0), 0.0)
    corrected['positive'] = max(min(corrected['positive'] + positive_adjustment, 1.0), 0.0)
    corrected['neutral'] = max(corrected['neutral'] + neutral_adjustment, 0.0)

    # æ­£è¦åŒ–ï¼ˆåˆè¨ˆã‚’1.0ã«ï¼‰
    total = corrected['positive'] + corrected['negative'] + corrected['neutral']
    if total > 0:
        corrected['positive'] /= total
        corrected['negative'] /= total
        corrected['neutral'] /= total

    # ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ«ãƒ¼ãƒ«è£œæ­£ã¯é‡è¦ãªæƒ…å ±ãªã®ã§INFOãƒ¬ãƒ™ãƒ«ï¼‰
    if corrections_applied:
        logger.info(f'ãƒ«ãƒ¼ãƒ«è£œæ­£é©ç”¨: {", ".join(corrections_applied)} | '
                   f'èª¿æ•´å€¤ pos:{positive_adjustment:+.2f} neg:{negative_adjustment:+.2f} | '
                   f'çµæœ P:{corrected["positive"]:.3f} N:{corrected["negative"]:.3f} Neu:{corrected["neutral"]:.3f}')

    return corrected


def _single_model_inference(text: str, model, tokenizer, id2label) -> dict:
    """
    Perform inference using a single model.
    Returns probability scores for pos, neg, neutral.
    """
    if model is None or tokenizer is None:
        return None

    try:
        inputs = tokenizer(
            text,
            padding=True,
            truncation=True,
            max_length=MAX_LENGTH,
            return_tensors='pt'
        )
        inputs = {k: v.to(_device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            probabilities = torch.softmax(outputs.logits, dim=-1)[0]

        scores = probabilities.cpu().numpy()

        # Handle different model configurations
        if len(scores) == 3:
            if id2label and id2label.get(0) == 'negative':
                # Format: 0=negative, 1=neutral, 2=positive
                return {
                    "positive": float(scores[2]),
                    "negative": float(scores[0]),
                    "neutral": float(scores[1])
                }
            else:
                return {
                    "positive": float(scores[1]),
                    "negative": float(scores[0]),
                    "neutral": float(scores[2])
                }
        elif len(scores) == 2:
            # Binary model (kit-nlp: 0=ãƒã‚¸ãƒ†ã‚£ãƒ–, 1=ãƒã‚¬ãƒ†ã‚£ãƒ–)
            if id2label and (id2label.get(0) == 'ãƒã‚¸ãƒ†ã‚£ãƒ–' or id2label.get(0, '').lower() == 'positive'):
                return {
                    "positive": float(scores[0]),
                    "negative": float(scores[1]),
                    "neutral": 0.0
                }
            else:
                return {
                    "positive": float(scores[1]),
                    "negative": float(scores[0]),
                    "neutral": 0.0
                }
        else:
            return {"positive": 0.33, "negative": 0.33, "neutral": 0.34}
    except Exception as e:
        logger.warning(f'Model inference error: {e}')
        return None


def _pytorch_inference(text: str, language: str) -> dict:
    """
    Perform inference using PyTorch.
    For Japanese: ensemble of 2 models (christian-phu + kit-nlp)
    For other languages: XLM-RoBERTa

    Args:
        text: Preprocessed text
        language: Language code ('ja' or 'other')

    Returns:
        dict: {"positive": float, "negative": float, "neutral": float}
    """
    global _ja_model_1, _ja_tokenizer_1, _ja_id2label_1
    global _ja_model_2, _ja_tokenizer_2, _ja_id2label_2
    global _multi_model, _multi_tokenizer, _multi_id2label

    if language == 'ja':
        # Ensemble for Japanese: average of 2 models
        result_1 = _single_model_inference(text, _ja_model_1, _ja_tokenizer_1, _ja_id2label_1)
        result_2 = _single_model_inference(text, _ja_model_2, _ja_tokenizer_2, _ja_id2label_2)

        if result_1 is not None and result_2 is not None:
            # Average both models (kit-nlp has neutral=0, so it contributes less to neutral)
            return {
                "positive": (result_1["positive"] + result_2["positive"]) / 2,
                "negative": (result_1["negative"] + result_2["negative"]) / 2,
                "neutral": (result_1["neutral"] + result_2["neutral"]) / 2
            }
        elif result_1 is not None:
            return result_1
        elif result_2 is not None:
            return result_2
        else:
            # Fallback to rule-based
            label = _rule_based_classify(text)
            if label == 'pos':
                return {"positive": 0.6, "negative": 0.15, "neutral": 0.25}
            else:
                return {"positive": 0.15, "negative": 0.6, "neutral": 0.25}
    else:
        # Multilingual model for other languages
        result = _single_model_inference(text, _multi_model, _multi_tokenizer, _multi_id2label)
        if result is not None:
            return result
        else:
            label = _rule_based_classify(text)
            if label == 'pos':
                return {"positive": 0.6, "negative": 0.15, "neutral": 0.25}
            else:
                return {"positive": 0.15, "negative": 0.6, "neutral": 0.25}


def classify_comment(text: str) -> dict:
    """
    Classify sentiment for a single comment with language detection.
    For Japanese: uses ensemble of 2 models (christian-phu + kit-nlp)
    For other languages: uses XLM-RoBERTa
    Returns probability scores for positive, negative, and neutral.

    Args:
        text: Comment text

    Returns:
        dict: {"positive": float, "negative": float, "neutral": float, "language": str}
    """
    if not text or not text.strip():
        return {"positive": 0.33, "negative": 0.33, "neutral": 0.34, "language": "unknown"}

    processed_text = _preprocess_text(text)
    if not processed_text:
        return {"positive": 0.33, "negative": 0.33, "neutral": 0.34, "language": "unknown"}

    # Detect language
    language = _detect_language(processed_text)

    # Use PyTorch inference with appropriate model (ensemble for Japanese)
    result = _pytorch_inference(processed_text, language)

    result["language"] = language

    return result


def _classify_comment_rules_only(text: str) -> dict:
    """
    Classify sentiment using rules only (fallback mode).
    Returns scores in the same format as model-based classification.

    Args:
        text: Comment text

    Returns:
        dict: {"positive": float, "negative": float, "neutral": float, "language": str}
    """
    if not text or not text.strip():
        return {"positive": 0.33, "negative": 0.33, "neutral": 0.34, "language": "unknown"}

    processed_text = _preprocess_text(text)
    if not processed_text:
        return {"positive": 0.33, "negative": 0.33, "neutral": 0.34, "language": "unknown"}

    language = _detect_language(processed_text)
    label = _rule_based_classify(processed_text)

    # Convert rule-based label to scores
    if label == 'pos':
        base_scores = {"positive": 0.6, "negative": 0.15, "neutral": 0.25}
    else:
        base_scores = {"positive": 0.15, "negative": 0.6, "neutral": 0.25}

    # Apply rule adjustments for more nuanced scoring
    adjusted = _adjust_sentiment_with_rules(processed_text, base_scores)
    adjusted["language"] = language

    return adjusted


def classify_comments(comments: list[dict]) -> list[dict]:
    """
    Classify sentiment for a list of comments.

    Args:
        comments: List of comment dicts

    Returns:
        List of comment dicts with 'sentiment' field added

    Raises:
        RuntimeError: If all models failed to load and FALLBACK_TO_RULES_ONLY is False
    """
    # Load models once at the beginning
    load_models()

    # Check if at least one model loaded successfully
    all_models_failed = _ja_model_1 is None and _ja_model_2 is None and _multi_model is None

    if all_models_failed:
        if FALLBACK_TO_RULES_ONLY:
            logger.warning('å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã¿ã§æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚')
            for comment in comments:
                comment['sentiment'] = _classify_comment_rules_only(comment.get('text', ''))
            return comments
        else:
            error_msg = 'å…¨ã¦ã®æ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç’°å¢ƒå¤‰æ•°ã¨ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚FALLBACK_TO_RULES_ONLY=true ã§ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’æœ‰åŠ¹åŒ–ã§ãã¾ã™ã€‚'
            logger.error(error_msg)
            raise RuntimeError(error_msg)

    # Process comments sequentially (no parallel processing)
    for comment in comments:
        comment['sentiment'] = classify_comment(comment.get('text', ''))

    return comments
