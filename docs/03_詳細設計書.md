# 詳細設計書
YouTube分析バッチシステム

## 1. 設計方針
- I/Oとロジックを分離
- 単体テスト前提
- main処理は薄く保つ

## 2. モジュール構成

```
app/
├── main.py          # エントリーポイント
├── fetch/           # データ取得
│   └── youtube.py
├── sentiment/       # 感情分析
│   └── analyzer.py
├── aggregate/       # 集計処理
│   └── summarizer.py
└── repository/      # DB操作
    └── mysql.py
```

## 3. 関数仕様

### 3.1 fetch/youtube.py

```python
def fetch_video(video_id: str) -> dict | None:
    """
    動画メタ情報を取得する

    Args:
        video_id: YouTube動画ID
    Returns:
        動画情報の辞書、取得失敗時はNone
    """

def fetch_comments(video_id: str, comment_limit: int = 10) -> list[dict]:
    """
    コメントを取得する（いいね数順）

    Args:
        video_id: YouTube動画ID
        comment_limit: 取得件数（デフォルト10）
    Returns:
        コメント情報のリスト
    """
```

### 3.2 sentiment/analyzer.py

**感情分析モデル**:
- **日本語モデル1**: `christian-phu/bert-finetuned-japanese-sentiment` (3クラス)
- **日本語モデル2**: `kit-nlp/bert-base-japanese-sentiment-irony` (2クラス、皮肉検出)
- **多言語モデル**: `cardiffnlp/twitter-xlm-roberta-base-sentiment` (Twitter特化)
- **推論方式**: PyTorch推論（`torch.no_grad()`, CPU専用）
- **分類**: 3値分類（pos / neg / other）
- **最適化**: `torch.set_num_threads(1)`, `max_length=128`
- **アンサンブル**: 日本語は2モデル組み合わせ、その他は多言語モデル
- **ルールベース**: 200以上のパターンマッチングで補完

```python
def load_models() -> None:
    """
    感情分析モデルをロードする（起動時に1回のみ）
    3つの公開モデルをHugging Faceからロード
    """

def classify_comment(text: str) -> dict:
    """
    コメントの感情を分類する（3値スコア）

    Args:
        text: コメント本文
    Returns:
        {
            "positive": float,   # 0.0-1.0
            "negative": float,   # 0.0-1.0
            "neutral": float,    # 0.0-1.0
            "language": str      # "ja" | "other"
        }

    Notes:
        - 言語検出により適切なモデルを選択
        - PyTorch推論を使用（torch.no_grad()で最適化）
        - モデルロード失敗時はルールベース分類にフォールバック
    """

def classify_comments(comments: list[dict]) -> list[dict]:
    """
    コメントリストに感情分類を一括付与する

    Args:
        comments: コメント情報のリスト
    Returns:
        各コメントに'sentiment'フィールド（dict）が追加されたリスト
        sentiment = {"positive": float, "negative": float, "neutral": float, "language": str}

    Notes:
        - 各コメントに対して言語検出と適切なモデル選択を実施
        - モデルは起動時に1回だけロード
        - ルールベース分類で補完
    """
```

### 3.3 aggregate/summarizer.py

```python
def aggregate_video(video: dict, comments: list[dict]) -> dict:
    """
    動画単位で感情分析結果を集計する（3値スコア平均）

    Args:
        video: 動画情報
        comments: 感情分類済みコメントのリスト
    Returns:
        集計結果の辞書
        {
            "video_id": str,
            "total_comments": int,
            "positive_score": float,   # 0.0-1.0（平均確率）
            "negative_score": float,   # 0.0-1.0（平均確率）
            "neutral_score": float,    # 0.0-1.0（平均確率）
            "analyzed_at": str         # ISO 8601形式
        }

    Notes:
        - 各コメントの確率スコアの平均値を算出
        - positive_score + negative_score + neutral_score ≈ 1.0
    """
```

### 3.4 repository/mysql.py

```python
def save_video(video: dict) -> None:
    """
    動画情報をMySQLに保存（UPSERT）

    Args:
        video: 動画情報の辞書
    """

def save_summary(summary: dict) -> None:
    """
    集計結果をMySQLに保存（UPSERT）

    Args:
        summary: 集計結果の辞書
    """

def get_connection() -> Connection:
    """MySQL接続を取得する"""
```

### 3.5 main.py

```python
def main(video_ids: list[str], comment_limit: int, use_cache: bool = True) -> None:
    """
    バッチ処理のエントリーポイント

    Args:
        video_ids: 処理対象の動画IDリスト
        comment_limit: コメント取得件数
        use_cache: JSONキャッシュを使用するか（デフォルト: True）
    """
```
